{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd045819cfb92a21706ccd5013156336b3b4a2ef9690da4bc6190484f558d2f6d31",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "45819cfb92a21706ccd5013156336b3b4a2ef9690da4bc6190484f558d2f6d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import functools\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras import metrics, losses\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bubble_detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "features = scaler.fit_transform(df.iloc[:,1:-1])\n",
    "output = np.array(df.iloc[:,-1], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 36\n",
    "x = []\n",
    "y = []\n",
    "for row in range(len(features) - time_steps):\n",
    "    x.append(features[row : row + time_steps])\n",
    "    y.append(output[row + time_steps - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, dtype = 'float64')\n",
    "y = np.array(y, dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=202144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9460431654676259"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "1 - sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Bidirectional(LSTM(units=50,\n",
    "                    input_shape=(x_train.shape[1], x_train.shape[2]),\n",
    "                    recurrent_activation='sigmoid',\n",
    "                    recurrent_initializer='glorot_uniform')),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "            loss=binary_focal_loss(alpha=0.75),\n",
    "            metrics=[metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 556 samples\n",
      "556/556 [==============================] - 5s 8ms/sample - loss: 0.0394 - binary_accuracy: 0.9424 - precision: 0.2500 - recall: 0.0333\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b0d6526d0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbidirectional (Bidirectional multiple                  25200     \n_________________________________________________________________\ndense (Dense)                multiple                  101       \n=================================================================\nTotal params: 25,301\nTrainable params: 25,301\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_output = pd.DataFrame(data = {'p': model.predict(x_test).flatten(), 'reference': y_test})\n",
    "prob_output.to_csv('rnn_prob_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[134,   0],\n",
       "       [  6,   0]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported from: https://github.com/aldi-dimara/keras-focal-loss/blob/master/focal_loss.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 19 08:20:58 2018\n",
    "@OS: Ubuntu 18.04\n",
    "@IDE: Spyder3\n",
    "@author: Aldi Faizal Dimara (Steam ID: phenomos)\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss from the paper in multiclass classification\n",
    "    Formula:\n",
    "        loss = -alpha_t*((1-p_t)^gamma)*log(p_t)\n",
    "        \n",
    "        p_t = y_pred, if y_true = 1\n",
    "        p_t = 1-y_pred, otherwise\n",
    "        \n",
    "        alpha_t = alpha, if y_true=1\n",
    "        alpha_t = 1-alpha, otherwise\n",
    "        \n",
    "        cross_entropy = -log(p_t)\n",
    "    Parameters:\n",
    "        alpha -- the same as wighting factor in balanced cross entropy\n",
    "        gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "        gamma -- 2.0 as mentioned in the paper\n",
    "        alpha -- 0.25 as mentioned in the paper\n",
    "    \"\"\"\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1-y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true)*alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1-alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1-p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss"
   ]
  }
 ]
}